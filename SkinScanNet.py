# -*- coding: utf-8 -*-
"""Skin_BS32_IS128_EP20*******.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10Y7zFvyy-8u9aIfTviYyT0cJJcHfmRL4
"""

# Commented out IPython magic to ensure Python compatibility.
import os
import numpy as np
import pandas as pd
import seaborn as sns
import tensorflow as tf
import matplotlib as plt
import matplotlib.pyplot as plt
from PIL import Image
from IPython.display import HTML
from urllib.request import urlopen
from tensorflow.keras import models, layers
from sklearn.metrics import confusion_matrix
# %matplotlib inline

!kaggle datasets download -d hasnainjaved/melanoma-skin-cancer-dataset-of-10000-images

!unzip /content/melanoma-skin-cancer-dataset-of-10000-images.zip

for dirname, _, filenames in os.walk('/content/melanoma_cancer_dataset/train'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

BATCH_SIZE = 32
IMAGE_SIZE = 128
CHANNELS = 3
EPOCHS = 20

dataset = tf.keras.preprocessing.image_dataset_from_directory(
    "/content/melanoma_cancer_dataset/train",
    seed=123,
    shuffle=True,
    image_size=(IMAGE_SIZE, IMAGE_SIZE),
    batch_size=BATCH_SIZE
)

class_names = dataset.class_names
class_names

for image_batch, label_batch in dataset.take(1):
    print(image_batch.shape)
    print(label_batch.numpy())

    for image_batch, label_batch in dataset.take(1):
     print(image_batch[0].numpy())

plt.figure(figsize=(6, 6))
for image_batch, labels_batch in dataset.take(1):
    for i in range(9):
        ax = plt.subplot(3, 3, i + 1)
        plt.imshow(image_batch[i].numpy().astype("uint8"))
        plt.title(class_names[labels_batch[i]])
        plt.axis("off")
plt.show()

len(dataset)

train_size = 0.8
len(dataset)*train_size

train_ds = dataset.take(100)
len(train_ds)

test_ds = dataset.skip(100)
len(test_ds)

val_size=0.1
len(dataset)*val_size

val_ds = test_ds.take(12)
len(val_ds)

test_ds = test_ds.skip(12)
len(test_ds)

def get_dataset_partitions_tf(ds, train_split=0.8, val_split=0.1, test_split=0.1, shuffle=True, shuffle_size=1000):
    assert (train_split + val_split + test_split) == 1
    ds_size = len(ds)

    if shuffle:
        ds = ds.shuffle(shuffle_size, seed=123)

    train_size = int(train_split * ds_size)
    val_size = int(val_split * ds_size)

    train_ds = ds.take(train_size)
    val_ds = ds.skip(train_size).take(val_size)
    test_ds = ds.skip(train_size).skip(val_size)

    return train_ds, val_ds, test_ds

train_ds, val_ds, test_ds = get_dataset_partitions_tf(dataset)

len(train_ds)

len(val_ds)

len(test_ds)

train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)
val_ds = val_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)
test_ds = test_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)

resize_and_rescale = tf.keras.Sequential([
  layers.Resizing(IMAGE_SIZE, IMAGE_SIZE),
  layers.Rescaling(1./255),
])

data_augmentation = tf.keras.Sequential([
  layers.RandomFlip("horizontal_and_vertical"),
  layers.RandomRotation(0.2),
])

train_ds = train_ds.map(
    lambda x, y: (data_augmentation(x, training=True), y)
).prefetch(buffer_size=tf.data.AUTOTUNE)

input_shape = (BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, CHANNELS)
n_classes = 2

model = tf.keras.Sequential([
    resize_and_rescale,

    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMAGE_SIZE, IMAGE_SIZE, CHANNELS)),
    tf.keras.layers.MaxPooling2D(),

    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D(),

    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D(),

    layers.Flatten(),

    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(2, activation='softmax')
])

model.build(input_shape=(BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, CHANNELS))

model.summary()

model.compile(
    optimizer='adam',
    loss=tf.keras.losses.SparseCategoricalCrossentropy(),
    metrics=['accuracy']
)
history = model.fit(
    train_ds,
    batch_size=BATCH_SIZE,
    validation_data=val_ds,
    verbose=1,
    epochs=50,
)

scores = model.evaluate(test_ds)

scores = model.evaluate(test_ds)
print(f"Test accuracy: {scores[1]*100:.2f}%")

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs_range = range(EPOCHS)

model.save('skin_cancer_model.h5')

model = tf.keras.models.load_model('/content/skin_cancer_model.h5')

history
history.params
history.history.keys()

type(history.history['loss'])
len(history.history['loss'])

history.history['accuracy'][:5]

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

loss = history.history['loss']
val_loss = history.history['val_loss']

plt.figure(figsize=(14, 3))
plt.subplot(1, 2, 1)
epochs_range = range(1, len(acc) + 1)
plt.plot(epochs_range, acc, label='Training Accuracy', color='#e60049')
plt.plot(epochs_range, val_acc, label='Validation Accuracy', color='#00bfa0')
plt.legend(loc='lower right')
#plt.title('Training and Validation Accuracy')
plt.xlabel('Epochs', fontweight='bold')
plt.ylabel('Accuracy', fontweight='bold')
plt.show()

plt.figure(figsize=(14, 3))
plt.subplot(1, 2, 1)
epochs_range = range(1, len(loss) + 1)
plt.plot(epochs_range, loss, label='Training Loss', color='#e60049')
plt.plot(epochs_range, val_loss, label='Validation Loss', color='#00bfa0')
plt.legend(loc='upper right')
#plt.title('Training and Validation Loss')
plt.xlabel('Epochs', fontweight='bold')
plt.ylabel('Loss', fontweight='bold')
plt.show()

def make_gradcam_pp_heatmap(img_array, model, last_conv_layer_name, pred_index=None):
    grad_model = tf.keras.models.Model(
        inputs=[model.inputs],
        outputs=[model.get_layer(last_conv_layer_name).output, model.output]
    )

    with tf.GradientTape() as tape:
        last_conv_layer_output, preds = grad_model(img_array)
        if pred_index is None:
            pred_index = tf.argmax(preds[0])
        class_channel = preds[:, pred_index]

    grads = tape.gradient(class_channel, last_conv_layer_output)

    first = tf.exp(class_channel) * grads
    second = tf.exp(class_channel) * grads * grads
    third = tf.exp(class_channel) * grads * grads * grads
    global_sum = tf.reduce_sum(last_conv_layer_output, axis=(0, 1, 2))

    alpha_num = second
    alpha_denom = 2 * second + third * global_sum[:, None, None]
    alpha_denom = tf.where(alpha_denom != 0.0, alpha_denom, tf.ones(alpha_denom.shape))

    alphas = alpha_num / alpha_denom
    weights = tf.reduce_sum(alphas * tf.nn.relu(grads), axis=(0, 1))

    cam = tf.reduce_sum(tf.nn.relu(weights * last_conv_layer_output), axis=-1)
    heatmap = tf.squeeze(cam)
    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)
    return heatmap.numpy()

def display_gradcam(img, heatmap, alpha=0.4):
    heatmap = np.uint8(255 * heatmap)

    jet = plt.cm.get_cmap("jet")
    jet_colors = jet(np.arange(256))[:, :3]
    jet_heatmap = jet_colors[heatmap]

    jet_heatmap = tf.keras.preprocessing.image.array_to_img(jet_heatmap)
    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))
    jet_heatmap = tf.keras.preprocessing.image.img_to_array(jet_heatmap)

    superimposed_img = jet_heatmap * alpha + img
    superimposed_img = tf.keras.preprocessing.image.array_to_img(superimposed_img)

    plt.imshow(superimposed_img)
    plt.axis("off")
    plt.show()

for images_batch, labels_batch in test_ds.take(1):
    img_array = images_batch[0].numpy().astype("uint8")
    img_batch = np.expand_dims(img_array, axis=0)

    heatmap = make_gradcam_pp_heatmap(img_batch, model, last_conv_layer_name="conv2d_2")

    plt.figure(figsize=(6, 6))
    plt.imshow(img_array)
    plt.title(f"Actual: {class_names[labels_batch[0]]}")
    plt.axis("off")
    plt.show()

    display_gradcam(img_array, heatmap)

for images_batch, labels_batch in test_ds.take(1):

    first_image = images_batch[0].numpy().astype('uint8')
    first_label = labels_batch[0].numpy()

    print("First image to predict")
    plt.imshow(first_image)
    print("Actual label:", class_names[first_label])

    batch_prediction = model.predict(images_batch)
    print("Predicted label:", class_names[np.argmax(batch_prediction[0])])

def predict(model, img):
    img_array = tf.keras.preprocessing.image.img_to_array(img)
    img_array = tf.expand_dims(img_array, 0)
    predictions = model.predict(img_array)
    predicted_class = class_names[np.argmax(predictions[0])]
    confidence = round(100 * np.max(predictions[0]), 2)
    return predicted_class, confidence

actual_classes = []
predicted_classes = []

plt.figure(figsize=(15, 15))
for images, labels in test_ds.take(1):
    for i in range(9):
        ax = plt.subplot(3, 3, i + 1)
        plt.imshow(images[i].numpy().astype("uint8"))

        predicted_class, confidence = predict(model, images[i].numpy())
        actual_class = class_names[labels[i]]
        actual_classes.append(actual_class)
        predicted_classes.append(predicted_class)

        plt.title(f"Actual: {actual_class},\n Predicted: {predicted_class}.\n Confidence: {confidence}%")

        plt.axis("off")

print("Actual Classes:", actual_classes)
print("Predicted Classes:", predicted_classes)

Y_true = []
Y_pred = []
for images, labels in test_ds:
    for i in range(len(labels)):
        predicted_class, confidence = predict(model, images[i].numpy())
        Y_true.append(class_names[labels[i]])
        Y_pred.append(predicted_class)

cm = confusion_matrix(Y_true, Y_pred)
plt.figure(figsize=(7, 7))
sns.heatmap(cm, cmap='Blues', annot=True, square=True, xticklabels=class_names, yticklabels=class_names)
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.show()

im_file = urlopen("https://i.ibb.co.com/mGjNnps/melanoma-10000.jpg")
image_file = Image.open(im_file)
plt.figure(figsize=(15, 15))

i = 0

ax = plt.subplot(3, 3, i + 1)
plt.imshow(image_file)
predicted_class, confidence = predict(model, np.array(image_file))
plt.title(f"Predicted: {predicted_class}.\n Confidence: {confidence}%")
plt.axis("off")
plt.show()

im_file = urlopen("https://i.ibb.co.com/fNym6zT/melanoma-10005.jpg")
image_file = Image.open(im_file)
plt.figure(figsize=(15, 15))

i = 0

ax = plt.subplot(3, 3, i + 1)
plt.imshow(image_file)
predicted_class, confidence = predict(model, np.array(image_file))
plt.title(f"Predicted: {predicted_class}.\n Confidence: {confidence}%")
plt.axis("off")
plt.show()

im_file = urlopen("https://i.ibb.co/fNym6zT/melanoma-10005.jpg")
image_file = Image.open(im_file)
plt.figure(figsize=(15, 15))

image_file_resized = image_file.resize((IMAGE_SIZE, IMAGE_SIZE))
image_file_np = np.array(image_file_resized)

ax = plt.subplot(3, 3, 1)
plt.imshow(image_file_np)

predicted_class, confidence = predict(model, image_file_np)
plt.title(f"Predicted: {predicted_class}.\n Confidence: {confidence}%")
plt.axis("off")
plt.show()

heatmap = make_gradcam_pp_heatmap(np.expand_dims(image_file_np, axis=0), model, last_conv_layer_name="conv2d_2")
display_gradcam(image_file_np, heatmap)